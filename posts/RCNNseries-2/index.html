<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>RCNN-series-in-object-detection(续) | 自拙集</title><meta name="keywords" content="computer vision,deep learning,object detection,semantic segmentation"><meta name="author" content="Richard YU"><meta name="copyright" content="Richard YU"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="About自Faster R-CNN后，基于深度学习的目标检测框架大致形成，且精度也较为不错。在这之后，围绕着对图像数据更深层次理解，以及根据现有结构进行改进成为了一个主流点。 Speed&#x2F;accuracy trade-offs for modern convolutional object detectors object detection in 20 years: a survey  IoU">
<meta property="og:type" content="article">
<meta property="og:title" content="RCNN-series-in-object-detection(续)">
<meta property="og:url" content="http://densecollections.top/posts/RCNNseries-2/index.html">
<meta property="og:site_name" content="自拙集">
<meta property="og:description" content="About自Faster R-CNN后，基于深度学习的目标检测框架大致形成，且精度也较为不错。在这之后，围绕着对图像数据更深层次理解，以及根据现有结构进行改进成为了一个主流点。 Speed&#x2F;accuracy trade-offs for modern convolutional object detectors object detection in 20 years: a survey  IoU">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://images.unsplash.com/photo-1608153498891-e895052f0cbe?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80">
<meta property="article:published_time" content="2020-01-10T02:51:19.000Z">
<meta property="article:modified_time" content="2020-09-26T12:46:10.014Z">
<meta property="article:author" content="Richard YU">
<meta property="article:tag" content="computer vision">
<meta property="article:tag" content="deep learning">
<meta property="article:tag" content="object detection">
<meta property="article:tag" content="semantic segmentation">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://images.unsplash.com/photo-1608153498891-e895052f0cbe?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://densecollections.top/posts/RCNNseries-2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="preconnect" href="//zz.bdstatic.com"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: Richard YU","link":"链接: ","source":"来源: 自拙集","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2020-09-26 20:46:10'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="自拙集" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://raw.githubusercontent.com/Richardyu114/minds-thoughts-and-resources-about-research-/master/images/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">54</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/PaperStation/"><i class="fa-fw fas fa-edit"></i><span> PaperStation</span></a></div><div class="menus_item"><a class="site-page" href="/MindWandering/"><i class="fa-fw fas fa-paper-plane"></i><span> MindWandering</span></a></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://images.unsplash.com/photo-1608153498891-e895052f0cbe?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1350&amp;q=80)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">自拙集</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/PaperStation/"><i class="fa-fw fas fa-edit"></i><span> PaperStation</span></a></div><div class="menus_item"><a class="site-page" href="/MindWandering/"><i class="fa-fw fas fa-paper-plane"></i><span> MindWandering</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">RCNN-series-in-object-detection(续)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-01-10T02:51:19.000Z" title="发表于 2020-01-10 10:51:19">2020-01-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-09-26T12:46:10.014Z" title="更新于 2020-09-26 20:46:10">2020-09-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>6分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="About"><a href="#About" class="headerlink" title="About"></a>About</h2><p>自Faster R-CNN后，基于深度学习的目标检测框架大致形成，且精度也较为不错。在这之后，围绕着对图像数据更深层次理解，以及根据现有结构进行改进成为了一个主流点。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1611.10012">Speed/accuracy trade-offs for modern convolutional object detectors</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.05055">object detection in 20 years: a survey</a></p>
<p> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1912.05190">IoU-uniform R-CNN: Breaking Through the Limitations of RPN</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1909.02466v2.pdf">https://arxiv.org/pdf/1909.02466v2.pdf</a></p>
<h2 id="R-FCN"><a href="#R-FCN" class="headerlink" title="R-FCN"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1605.06409">R-FCN</a></h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>内容有参考：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arleyzhang.github.io/articles/7e6bc4a/">blog1</a></li>
</ul>
<a id="more"></a>
<h3 id="Content"><a href="#Content" class="headerlink" title="Content"></a>Content</h3><h2 id="FPN"><a href="#FPN" class="headerlink" title="FPN"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1612.03144">FPN</a></h2><h3 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h3><p>Feature Pyramid Networks(FPN)考虑到了卷积神经网络中各个尺度特征图的作用，认为像Fast R-CNN和Faster R-CNN这样的目标检测网络只用了一个特征图去来做RoI 和搜寻proposal，不一定能很好地处理全部尺寸的物体，虽然这种方式是为了speed-acc之间的trade off。作者认为，网络越深层产出的特征图往往语义信息越高，但是位置信息比较模糊，对小目标检测来说不太好；浅层的特征图提取出来的特征都是比较低级的边缘，纹理信息，但是分辨率好，位置信息得到了保留，因此将这些特征图结合起来，充分利用到高层语义信息，同时也不丢掉位置信息，应当能很大程度上提高检测的精度和鲁棒性。</p>
<p>博客内容有参考：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://vision.cornell.edu/se3/wp-content/uploads/2017/07/fpn-poster.pdf">FPN在CVPR的poster</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34144226">blog1</a>, <a target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2017-07-25-2">blog2</a>, <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/61536443">blog3</a></li>
</ul>
<h3 id="Content-1"><a href="#Content-1" class="headerlink" title="Content"></a>Content</h3><p>为了让各个尺寸的物体都能很好的检测到，以往的工作提出了图像金字塔，利用不同大小的图像尺寸进行滑窗，到了深度学习时代，直接通过神经网络输出的高层特征图，进行对应特征上的检测分类，之后考虑到尺度问题，开始挑选网络中产出的几个level的feature  map，分别进行检测，然后合并筛选给出最后的结果。FPN认为，既然检测既需要高层的特征便于分类和统筹全局观念，又需要特征图具有一定的分辨率去定位物体的图像位置，那么应该想个办法将这两个重要信息结合起来。但是在网络的前向传播中，这两者是矛盾的，低层的特征图特征抽象度不够，高层的特征图物体分辨率过低。我想，作者应该是受到当时resnet等跳级连接和FCN，U-Net等语义分割模型的启发，通过下采样提取高级特征，上采样恢复尺度，同时侧级连接补充位置信息，然后在每个上采样的特征图上进行检测来覆盖到各个物体（这一点借鉴了SSD）。</p>
<p><img src="/.top//various_pyramid_ways_in_cv.PNG" alt="目标检测中的金字塔模型"></p>
<p>如果没有每个特征图的预测，乍看就是FCN的经典结构。不过FPN的侧重点是为了结合高级语义特征和位置信息，因此加了一些额外的卷积操作，让网络在梯度下降中去focus这一点。下采样过程属于正常的网络操作，上采样时每个特征图进行2倍放大（<strong>最近邻插值</strong>，非转置卷积），当然这个2倍是根据你的下采样倍数来的，一般都是2倍，然后侧向对应的不是直接加过来（FCN），也不是叠操作（U-Net），而且先用个$1 \times 1$卷积处理下采样的特征图，然后加在一起，最后再做个$3 \times 3$的卷积。$1 \times 1$的卷积是为了减少通道数（上采样的通道数是固定的），否则不能相加，同时我想可能也是去提取一下位置信息，$3 \times 3$的卷积是为了处理一下加在一起后的特征图的混叠效应，提取出两者的有用信息。</p>
<p>值得一提的是，作者在论文中也说了，按照解决问题的思想，这样的金字塔形式应当是最简单的，没有加入任何其他的复杂技巧，实验效果证明效果也足够好，简单又有效。</p>
<blockquote>
<p>Simplicity is central to our design and we have found that our model is robust to many design choices. We have experimented with more sophisticated blocks (e.g., using multilayer residual blocks [16] as the connections) and observed marginally better results. Designing better connection modules is not the focus of this paper, so we opt for the simple design described above.</p>
</blockquote>
<p><img src="/.top//FPN_architecture.PNG" alt="FPN的结构示意"></p>
<p>实验方面，FPN主要针对RPN和Fast R-CNN进行，通过ablation study论证了FPN结构的有效性，同时结构之间的各个部件都是必要的。其中 RPN 和 Fast RCNN 分别关注的是召回率和正检率，在这里对比的指标分别为 Average Recall(AR) 和 Average Precision(AP)，分别对比了不同尺度物体检测情况。</p>
<p>以resnet为例，不管第一次feature map的缩小（$7 \times 7$的卷积），用后面的$\left\{ C_{2}, C_{3}, C_{4}, C_{5} \right\}$。对RPN来说，只用了$C_{4}$去生成预选框，然后利用pyramid of anchor去搜区域，由于FPN已经有了多尺度的作用，因此每个上采样的特征图中，会根据其特点设置一个固定size的anchor area，anchor aspect ratio还是保持[0.5, 1, 2]不变。为了照应到RPN中的512大小的anchor，FPN实验时多加了一个特征图（在$P_{5}$上下采样2倍），对应的区域大小和特征图level分别是：$\left\{ 32^{2}, 64^{2}, 128^{2}, 256^{2}, 512^{2} \right\} \longleftrightarrow \left\{ P_{2}, P_{3}, P_{4}, P_{5}, P_{6} \right\}$，用$P$代表上采样的特征图，便于区分下采样的$C$。从设置里可以看出，大特征图里找小物体，小特征图里找大物体。</p>
<p>实验Fast R-CNN时，固定FPN+RPN提取的proposal结果，在其中也加入FPN分别在$\left\{ P_{2}, P_{3}, P_{4}, P_{5} \right\}$中找物体做RoI Pooling，一样的，对于大尺度的RoI就用小的特征图，小尺度的RoI就用大的特征图。为了安排每个RoI Pooling尺度对应的特征图，作者给出如下公式：</p>
<script type="math/tex; mode=display">
k=\left\lfloor k_{0}+\log _{2}(\sqrt{w h} / 224)\right\rfloor</script><p>其中，224是ImageNet的标准输入尺寸，$k_{0} = 5$是基准值，代表最后一个特征图，$w, h$分别代表RoI区域（RPN+FPN给的原图的proposal）的宽和高。假设RoI大小是$112 \times 112$，那么$k=5-1=4$，就在$P_{4}$特征图上找，做RoI Pooling。一般来说proposal大小不固定，所以应该取整处理。</p>
<p>因为resnet的Conv5也作为特征金字塔的一部分，而原先的Fast R-CNN和Faster R-CNN在RoI Pooling后面才接上Conv5继续提取特征，所以论文简单的加了两个1024维的fc层在分类器和回归器之前，代替一下原先Conv5的工作。</p>
<p>最后在加入FPN的Faster  R-CNN中进行参数共享，检测精度也得到了一定的提升。具体实验结果直接看图，不再赘述。</p>
<p><img src="/.top//FPN_FasterRcnn.png" alt="图来自：https://github.com/unsky/FPN"></p>
<p><img src="/.top//FPN_experiments.PNG" alt="部分实验结果"></p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p><img src="/.top//FPN_QA.PNG" alt="FPN在CVPR现场QA"></p>
<p>FPN的贡献思想在于向上采样，融合了特征信息和位置信息，而且简洁有效。在这之后，何恺明率先利用FPN实现了Mask R-CNN，一统检测和实例分割，斩获马尔奖。现在FPN也被广泛使用，成为检测的必备组件（R-FCN由于自身设计缘故，无法加入FPN）。</p>
<p>但是，FPN设计中的上采样和侧向连接，其实主要是给小目标检测提供了帮助，因为主要是引入位置信息，然后放大特征图（实验结果也说明小目标检测精度提升多）。对于大目标来说，顶层特征图的高级语义固然重要，位置信息肯定还是没有底层特征图的多的，因此可以对一开始网络产出的浅层特征图跳级连接到顶层特征图，类似下面的结构（<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1803.01534">PANet</a>）：</p>
<p><img src="/.top//FPN_for_bigobject.jpg" alt="FPN针对大物体检测改进"></p>
<h2 id="RetinaNet"><a href="#RetinaNet" class="headerlink" title="RetinaNet"></a>RetinaNet</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/133317452">https://zhuanlan.zhihu.com/p/133317452</a></p>
<h2 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1912.04488.pdf">SOLO: Segmenting Objects by Locations</a></p>
<p><a target="_blank" rel="noopener" href="http://deeplearning.csail.mit.edu/instance_ross.pdf">http://deeplearning.csail.mit.edu/instance_ross.pdf</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Richard YU</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://densecollections.top/posts/RCNNseries-2/">http://densecollections.top/posts/RCNNseries-2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://densecollections.top" target="_blank">自拙集</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/computer-vision/">computer vision</a><a class="post-meta__tags" href="/tags/deep-learning/">deep learning</a><a class="post-meta__tags" href="/tags/object-detection/">object detection</a><a class="post-meta__tags" href="/tags/semantic-segmentation/">semantic segmentation</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5ff01204250e8048" async="async"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/Summaryofthisyear-1/"><img class="prev-cover" src="https://images.unsplash.com/photo-1608488426085-c8b7e9e4592f?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1351&amp;q=80" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">2019-2020:漫长的告别</div></div></a></div><div class="next-post pull-right"><a href="/posts/controlLinuxserver/"><img class="next-cover" src="https://images.unsplash.com/photo-1608153498891-e895052f0cbe?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1350&amp;q=80" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">尝试远程控制Ubuntu服务器</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/BriefreviewofObjectdetection/" title="A Brief Review of Object Detection and Semantic Segmentation"><img class="cover" src="https://images.unsplash.com/photo-1595769393754-418cb8bf6b14?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1355&q=80" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-02-27</div><div class="title">A Brief Review of Object Detection and Semantic Segmentation</div></div></a></div><div><a href="/posts/RCNNseries-1/" title="RCNN series in object detection"><img class="cover" src="https://images.unsplash.com/photo-1608488426085-c8b7e9e4592f?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1351&q=80" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-11-30</div><div class="title">RCNN series in object detection</div></div></a></div><div><a href="/posts/ssd-refinedet-paper/" title="SSD-RefineDet论文阅读"><img class="cover" src="https://images.unsplash.com/photo-1606870655612-8eacd813984d?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-08-03</div><div class="title">SSD-RefineDet论文阅读</div></div></a></div><div><a href="/posts/yolopaperreading/" title="yolo系列论文阅读笔记"><img class="cover" src="https://images.unsplash.com/photo-1608971222449-15661fc7bdb6?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=675&q=80" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-04</div><div class="title">yolo系列论文阅读笔记</div></div></a></div><div><a href="/posts/worksummaryofintern/" title="实习痰涂片项目总结"><img class="cover" src="https://images.unsplash.com/photo-1608488426085-c8b7e9e4592f?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1351&q=80" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-10-04</div><div class="title">实习痰涂片项目总结</div></div></a></div><div><a href="/posts/megviidlcourse/" title="旷视2017年深度学习实践课程"><img class="cover" src="https://images.unsplash.com/photo-1606870655612-8eacd813984d?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-02-25</div><div class="title">旷视2017年深度学习实践课程</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="https://raw.githubusercontent.com/Richardyu114/minds-thoughts-and-resources-about-research-/master/images/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Richard YU</div><div class="author-info__description">Today everything exists to end in a photograph</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">54</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Richardyu114"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://twitter.com/Yu1145635107" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a><a class="social-icon" href="https://instagram.com/d.h.richard" target="_blank" title="Instagram"><i class="fab fa-instagram-square"></i></a><a class="social-icon" href="https://weibo.com/u/5211687990" target="_blank" title="Weibo"><i class="fab fa-weibo"></i></a><a class="social-icon" href="https://www.douban.com/people/161993653/" target="_blank" title="豆瓣"><i class="fas fa-bookmark"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#About"><span class="toc-number">1.</span> <span class="toc-text">About</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#R-FCN"><span class="toc-number">2.</span> <span class="toc-text">R-FCN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Introduction"><span class="toc-number">2.1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Content"><span class="toc-number">2.2.</span> <span class="toc-text">Content</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#FPN"><span class="toc-number">3.</span> <span class="toc-text">FPN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Introduction-1"><span class="toc-number">3.1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Content-1"><span class="toc-number">3.2.</span> <span class="toc-text">Content</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion"><span class="toc-number">3.3.</span> <span class="toc-text">Conclusion</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RetinaNet"><span class="toc-number">4.</span> <span class="toc-text">RetinaNet</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Mask-R-CNN"><span class="toc-number">5.</span> <span class="toc-text">Mask R-CNN</span></a></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/ssd-refinedet-paper/" title="SSD-RefineDet论文阅读"><img src="https://images.unsplash.com/photo-1606870655612-8eacd813984d?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1350&amp;q=80" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SSD-RefineDet论文阅读"/></a><div class="content"><a class="title" href="/posts/ssd-refinedet-paper/" title="SSD-RefineDet论文阅读">SSD-RefineDet论文阅读</a><time datetime="2020-08-03T13:25:33.000Z" title="发表于 2020-08-03 21:25:33">2020-08-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/houjieC++STL/" title="侯捷c++STL体系结构与内核分析"><img src="https://images.unsplash.com/photo-1608488426085-c8b7e9e4592f?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1351&amp;q=80" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="侯捷c++STL体系结构与内核分析"/></a><div class="content"><a class="title" href="/posts/houjieC++STL/" title="侯捷c++STL体系结构与内核分析">侯捷c++STL体系结构与内核分析</a><time datetime="2020-06-12T08:24:02.000Z" title="发表于 2020-06-12 16:24:02">2020-06-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/yolopaperreading/" title="yolo系列论文阅读笔记"><img src="https://images.unsplash.com/photo-1608971222449-15661fc7bdb6?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=675&amp;q=80" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="yolo系列论文阅读笔记"/></a><div class="content"><a class="title" href="/posts/yolopaperreading/" title="yolo系列论文阅读笔记">yolo系列论文阅读笔记</a><time datetime="2020-06-04T01:53:54.000Z" title="发表于 2020-06-04 09:53:54">2020-06-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/houjieC++/" title="侯捷C++面向对象程序设计"><img src="https://images.unsplash.com/photo-1608153498891-e895052f0cbe?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1350&amp;q=80" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="侯捷C++面向对象程序设计"/></a><div class="content"><a class="title" href="/posts/houjieC++/" title="侯捷C++面向对象程序设计">侯捷C++面向对象程序设计</a><time datetime="2020-05-28T08:48:27.000Z" title="发表于 2020-05-28 16:48:27">2020-05-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/loopdetectioninBipartitegraph/" title="二分图搜无向定长环"><img src="https://images.unsplash.com/photo-1608971222449-15661fc7bdb6?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=675&amp;q=80" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="二分图搜无向定长环"/></a><div class="content"><a class="title" href="/posts/loopdetectioninBipartitegraph/" title="二分图搜无向定长环">二分图搜无向定长环</a><time datetime="2020-05-08T02:41:32.000Z" title="发表于 2020-05-08 10:41:32">2020-05-08</time></div></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://images.unsplash.com/photo-1608153498891-e895052f0cbe?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1350&amp;q=80)"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2021 By Richard YU</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">It's hard to tell that the world we live in is either a reality or a dream.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.spacingElementById('content-inner')
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.spacingElementById('content-inner')
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadValine () {
  function initValine () {
    let initData = {
      el: '#vcomment',
      appId: 'duGoywhUmLrx9pM6qQhmf47c-gzGzoHsz',
      appKey: 'm7fc8w4Di5qnAXXaJ5Gp3Pgg',
      placeholder: '欢迎评论！请留下你的邮箱',
      avatar: 'robohash',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign({}, initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script>(function(){
  const bp = document.createElement('script');
  const curProtocol = window.location.protocol.split(':')[0];
  if (curProtocol === 'https') {
    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
  bp.dataset.pjax = ''
  const s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(bp, s);
})()</script></div></body></html>